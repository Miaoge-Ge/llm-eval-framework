# LLM Evaluation Framework (LLM è¯„æµ‹æ¡†æ¶)

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)

è½»é‡çº§ã€é…ç½®é©±åŠ¨ä¸”æ˜“äºæ‰©å±•çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„æµ‹æ¡†æ¶ã€‚ä¸“ä¸ºé«˜æ•ˆå’Œæ˜“ç”¨æ€§è®¾è®¡ï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶å‘è¯„æµ‹ã€ç²¾ç¡®çš„é€Ÿç‡é™åˆ¶ä»¥åŠè¯¦å°½çš„æ€§èƒ½æŒ‡æ ‡åˆ†æã€‚

[English Documentation](README.md)

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **å¤šæ¨¡å‹ä¸å¤šä¾›åº”å•†æ”¯æŒ**ï¼šæ— ç¼åˆ‡æ¢ OpenAIã€DeepSeekã€ZhipuAI (GLM) ä»¥åŠå…¶ä»–å…¼å®¹ OpenAI æ¥å£çš„ APIã€‚
- **é«˜å¹¶å‘æ‰§è¡Œ**ï¼šåŸºäºå¤šçº¿ç¨‹çš„é«˜æ€§èƒ½è¯„æµ‹å¼•æ“ï¼Œæ”¯æŒè‡ªå®šä¹‰å¹¶å‘æ•°ã€‚
- **æ™ºèƒ½é€Ÿç‡é™åˆ¶**ï¼šå†…ç½®ä»¤ç‰Œæ¡¶ï¼ˆToken Bucketï¼‰ç®—æ³•ï¼Œæ”¯æŒç²¾ç¡®çš„ RPMï¼ˆæ¯åˆ†é’Ÿè¯·æ±‚æ•°ï¼‰å’Œ TPMï¼ˆæ¯åˆ†é’Ÿ Token æ•°ï¼‰æ§åˆ¶ã€‚
- **å¥å£®çš„é”™è¯¯å¤„ç†**ï¼šè‡ªåŠ¨é‡è¯•æœºåˆ¶ã€æ™ºèƒ½é”™è¯¯è§£æï¼Œä»¥åŠå¯¹è‡´å‘½ API é”™è¯¯ï¼ˆå¦‚è®¤è¯å¤±è´¥ã€è¶…é™ï¼‰çš„ä¼˜é›…å¤„ç†ä¸é€€å‡ºã€‚
- **ä¸°å¯Œçš„æŒ‡æ ‡ä½“ç³»**ï¼š
  - **å‡†ç¡®ç‡ (Accuracy/Pass@1)**
  - **ååé‡ (Throughput - Tokens/sec)**
  - **å»¶è¿Ÿ (Latency - å¹³å‡ä»»åŠ¡è€—æ—¶)**
  - **æ—¥å¿—åˆ†ç¦»**ï¼šç»“æœæ•°æ® (`results.tsv`) ä¸æ‰§è¡Œæ—¥å¿— (`execution.log`) åˆ†ç¦»ï¼Œä¾¿äºåˆ†æã€‚
- **å¯æ‰©å±•æ¶æ„**ï¼šé€šè¿‡ç»§æ‰¿åŸºç±»ï¼Œè½»æ¾æ·»åŠ æ–°çš„è¯„æµ‹ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€é€»è¾‘æ¨ç†ç­‰ï¼‰ã€‚
- **åˆ†å±‚é…ç½®ç³»ç»Ÿ**ï¼š`registry.yaml`ï¼ˆé™æ€èµ„æºï¼‰+ `settings.yaml`ï¼ˆè¿è¡Œæ—¶è¦†ç›–ï¼‰çš„åŒå±‚é…ç½®æ¶æ„ã€‚

## ğŸš€ æ”¯æŒçš„ä»»åŠ¡

- **ä»£ç ç”Ÿæˆ (Code Generation)**:
  - [HumanEval](https://github.com/openai/human-eval)
  - [MBPP](https://github.com/google-research/google-research/tree/master/mbpp)
- **æ•°å­¦æ¨ç† (Mathematical Reasoning)**:
  - [GSM8K](https://github.com/openai/grade-school-math)

## ğŸ“¦ å®‰è£…æŒ‡å—

1. **å…‹éš†ä»“åº“**
   ```bash
   git clone https://github.com/your-username/llm-eval-framework.git
   cd llm-eval-framework
   ```

2. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```

## âš™ï¸ é…ç½®æŒ‡å—

æœ¬æ¡†æ¶é‡‡ç”¨åŒå±‚é…ç½®ç³»ç»Ÿï¼š

1.  **`registry.yaml`**: å®šä¹‰å¯ç”¨çš„ä¾›åº”å•†ï¼ˆProvidersï¼‰ã€æ¨¡å‹ï¼ˆModelsï¼‰å’Œæ•°æ®é›†ï¼ˆDatasetsï¼‰ã€‚
2.  **`settings.yaml`**: æ§åˆ¶è¿è¡Œæ—¶è¡Œä¸ºï¼Œå¹¶å¯è¦†ç›–æ¨¡å‹å‚æ•°ã€‚

### 1. æ³¨å†Œèµ„æº (`registry.yaml`)

åœ¨æ­¤æ–‡ä»¶ä¸­å®šä¹‰æ‚¨çš„ API Key å’Œæ¨¡å‹ç«¯ç‚¹ã€‚

```yaml
providers:
  deepseek:
    api_key: "YOUR_DEEPSEEK_KEY"
    base_url: "https://api.deepseek.com"

models:
  deepseek-chat:
    provider: "deepseek"
    model_name: "deepseek-chat"

datasets:
  humaneval: "./dataset/HumanEval.jsonl"
```

### 2. è¿è¡Œæ—¶é…ç½® (`settings.yaml`)

é€‰æ‹©è¦è¿è¡Œçš„ä»»åŠ¡å’Œæ¨¡å‹ï¼Œå¹¶è°ƒæ•´æ€§èƒ½å‚æ•°ã€‚

```yaml
# é€‰æ‹©ä»»åŠ¡å’Œæ¨¡å‹
task: "humaneval"
selected_model: "deepseek-chat"

# æ‰§è¡Œè®¾ç½®
workers: 10          # å¹¶å‘çº¿ç¨‹æ•°
pass_k: 1            # Pass@k æŒ‡æ ‡ (é»˜è®¤: 1)

# è¿è¡Œæ—¶å‚æ•°è¦†ç›– (å¯é€‰)
temperature: 0.0     # è¦†ç›–æ¨¡å‹çš„ temperature
rpm_limit: 60        # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°
tpm_limit: 100000    # æ¯åˆ†é’Ÿæœ€å¤§ Token æ•°
```

## â–¶ï¸ ä½¿ç”¨æ–¹æ³•

è¿è¡Œè¯„æµ‹è„šæœ¬ï¼š

```bash
python run_eval.py
```

### è¾“å‡ºç»“æœ

è¯„æµ‹ç»“æœå°†ä¿å­˜åœ¨ `model_test/<model_name>/<task_name>_<timestamp>/` ç›®å½•ä¸‹ï¼š

- **`results.tsv`**: åˆ¶è¡¨ç¬¦åˆ†éš”çš„ä»»åŠ¡ç»“æœæ–‡ä»¶ï¼ˆåŒ…å«ä»»åŠ¡IDã€çŠ¶æ€ã€è€—æ—¶ã€Tokenæ•°ï¼‰ï¼Œæ˜“äº Excel/Pandas å¤„ç†ã€‚
- **`execution.log`**: å®Œæ•´çš„æ‰§è¡Œæ—¥å¿—ï¼ŒåŒ…å«è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ã€è­¦å‘Šå’Œæœ€ç»ˆæ‘˜è¦ã€‚

**æ§åˆ¶å°æ‘˜è¦ç¤ºä¾‹:**
```text
==================================================
Evaluation Summary
--------------------
Tasks Total: 164
Tasks Processed: 164
Passed: 100
Failed: 64
API Errors: 0
Accuracy: 60.98%

Performance Metrics
--------------------
Wall Clock Time: 01:10:05
Throughput: 1500.5 tokens/sec
Total Tokens: 125000

Results saved to: model_test/deepseek-chat/humaneval_20240101_120000
==================================================
```

## ğŸ› ï¸ æ·»åŠ æ–°ä»»åŠ¡

åªéœ€ç»§æ‰¿ `CodeGenerationTask` æˆ– `ReasoningTask` å³å¯è½»æ¾æ‰©å±•ã€‚

```python
from framework.core import CodeGenerationTask, TaskRegistry

@TaskRegistry.register("my_custom_task")
class MyTask(CodeGenerationTask):
    def process_item(self, item, llm_client):
        # åœ¨æ­¤å®ç°æ‚¨çš„è¯„æµ‹é€»è¾‘
        pass
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚
